{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC421: Homework #1\n",
    "\n",
    "\n",
    "\n",
    "## Problem 2.10: pg 65\n",
    "\n",
    "**2.10** Consider a modified version of the vacuum environment in Exercise 2.8, in which the agent is penalized one point for each movement.\n",
    "\n",
    "**a.** Can a simple reflex agent be perfectly rational for this environment? Explain.  \n",
    "**b.** What about a reflex agent with state? Design such an agent.  \n",
    "**c.** How do your answers to a and b change if the agent’s percepts give it the clean/dirty status of every square in the environment?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A)** A simple reflex agent cannot be perfect rational in this environment. Since the agent is penalized one point for each movement and the reflex agent has no history of what has already done, then the agent will eventually take unnecessary movements. Take for example the agent has cleaned both room A and room B and ends up in room B. At this point, it does not have any historical knowledge that it did this and will turn Left (according to the function map) and check if Room A again and repeat.   \n",
    "\n",
    "\n",
    "**b)**  A reflex agent with state cannot be perfectly rational for this environment because on its iteration it does not have any knowledge about the other room. Take example if Room A was dirty and Room B was clean and the agent started in Room A. The agent will sense that the room is dirty, and update it’s state to Room A being dirty. It will then suck the dirt given this state, and then it will then receive information from environment again. It will update it’s state to Room A being clean, and then turn right to check Room B. It will see that Room B is clean, update it’s state, and turn left to check Room A again, putting itself in a loop.\n",
    "\n",
    "```\n",
    "Function state-reflex-vacuum-agent([location,status]) returns an action\n",
    "\tIf status = Dirty then state = location Dirty\n",
    "\tElse state = location Clean\n",
    "\tIf location Dirty then return suck\n",
    "\tElse If location clean and location = A then return Right\n",
    "\tElse if location clean and location = B then return Left\n",
    "```\n",
    "\n",
    "**c)** If the agent’s percepts give it the clean/dirt of every square in the environment then it can perform perfectly rational. It can perform perfectly because the agent can have a reflex for every possible scenario. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.15 (a,b): pg 116\n",
    "\n",
    "**3.15** Consider a state space where the start state is number 1 and each state k has two successors: numbers 2k and 2k + 1.    \n",
    "\n",
    "**a.** Draw the portion of the state space for states 1 to 15.  \n",
    "**b.** Suppose the goal state is 11. List the order in which nodes will be visited for breadth-first search, depth-limited search with limit 3, and iterative deepening search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binarytree import Node, tree\n",
    "\n",
    "root = Node(1)    \n",
    "root.left = Node(2)\n",
    "root.right = Node(3)\n",
    "root.left.left = Node(4)\n",
    "root.left.right = Node(5)\n",
    "root.right.left = Node(6)\n",
    "root.right.right = Node(7)\n",
    "root.left.left.left = Node(8)\n",
    "root.left.left.right = Node(9)\n",
    "root.left.right.left = Node(10)\n",
    "root.left.right.right = Node(11)\n",
    "root.right.left.left = Node(12)\n",
    "root.right.left.right = Node(13)\n",
    "root.right.right.left = Node(14)\n",
    "root.right.right.right = Node(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ________1________\n",
      "       /                 \\\n",
      "    __2___             ___3___\n",
      "   /      \\           /       \\\n",
      "  4       _5        _6        _7\n",
      " / \\     /  \\      /  \\      /  \\\n",
      "8   9   10   11   12   13   14   15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)**   \n",
    "    **Breadth-first-search:** 1,2,3,4,5,6,7,8,9,10,11  \n",
    "    **Depth-Limited-search:** 1,2,4,8,9,5,10,11  \n",
    "    **Iterative-Deepening:**   \n",
    "       1st Iteration: 1  \n",
    "       2nd Iteration: 1,2,3  \n",
    "       3rd Iteration: 1,2,4,5,3,6,7  \n",
    "       4th Iteration: 1,2,4,8,9,5,10,11  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(root, goal):\n",
    "    queue = [root.value]\n",
    "    \n",
    "    while queue:\n",
    "        temp = queue.pop()\n",
    "        if temp == goal:\n",
    "            return goal\n",
    "        else:\n",
    "            queue.insert(0,root.left.value)\n",
    "            queue.insert(0,root.right.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (robenv)",
   "language": "python",
   "name": "robenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
